{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da74d1d4",
   "metadata": {},
   "source": [
    "# I. **Initial Set Up**\n",
    "\n",
    "## **Project on Evaluating Machine Learning Models.**\n",
    " \n",
    "**Instructions.** Select a dataset from [UCI](https://archive.ics.uci.edu/ml/datasets.php) or [Google](https://datasetsearch.research.google.com/), formulate a machine learning problem (supervised or unsupervised), and build and evaluate two models (different methods) that solve the problem. Any programming language may be used. \n",
    "- You may also use other legitimate sources at the same level of the UCI and Google sites provided. \n",
    "- You may use methods not taught in class. KNN is not an option. \n",
    "- You may also use a portion of the dataset if its size causes problems (e.g. reduce the number of rows)\n",
    "\n",
    "**Deliverables.** In a Google Drive folder that I can access, submit the following: \n",
    "- Source code and executables\n",
    "- Instructions on how to use your resources (i.e. your program)\n",
    "- Slide deck explaining your work\n",
    "- Recorded video presentation of your work (approx 20-30mins)\n",
    "\n",
    "**Expected Output.**\n",
    "- Jupyter Notebook (.ipynb)\n",
    "- Resources (csv unclean and cleaned)\n",
    "- Video Presentation\n",
    "- Slide Deck Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b589b",
   "metadata": {},
   "source": [
    "# **II. Data Set**\n",
    "\n",
    "**Dataset Overview.**\n",
    "\n",
    "The dataset contains raw information sourced from the Zomato Recommendation Platform for restaurants based in Pune, India, covering the year 2023. Each row corresponds to a single restaurant entry and includes a variety of attributes such as the restaurantâ€™s name, multiple types of cuisine offered (up to eight slots), its categorized food type, the average cost for two people, the locality within Pune, and the average customer dining rating.\n",
    "\n",
    "This dataset provides a foundation for predictive modeling and exploratory analysis, as it blends both categorical (e.g., cuisine types, locality) and numerical (e.g., rating, pricing) data. Through this structure, we can investigate patterns in consumer preferences, identify key factors influencing restaurant ratings, and evaluate the performance of machine learning models like Decision Trees and Mixed Naive Bayes in classifying highly rated restaurants.\n",
    "\n",
    "| **Features**              | **Short Explanation**                                                         | **Possible Values / Example**                 |\n",
    "| ------------------------ | ----------------------------------------------------------------------------- | --------------------------------------------- |\n",
    "| `Restaurant_Name`        | Name of the restaurant listed on Zomato                                       | `\"Le Plaisir\"`, `\"Savya Rasa\"`                |\n",
    "| `Cuisine1` to `Cuisine8` | Different types of cuisines offered by the restaurant, in order of prominence | `\"South Indian\"`, `\"Desserts\"`, `\"MISSING\"`   |\n",
    "| `Category`               | Grouped categories combining all cuisine types into a readable list           | `\"Cafe, Italian, Continental...\"`             |\n",
    "| `Pricing_for_2`          | Approximate cost for two people, in INR                                       | `600`, `1200`, `2100`                         |\n",
    "| `Locality in Pune`       | Location/neighborhood of the restaurant in Pune                               | `\"Koregaon Park\"`, `\"Baner\"`, `\"Viman Nagar\"` |\n",
    "| `Dining_Rating`          | Average customer rating of the restaurant (out of 5)                          | `4.2`, `3.8`, `4.9`                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480d0a8-e8d5-4114-8561-d17f7a9d5faa",
   "metadata": {},
   "source": [
    "# **III. Ideal Pipeline**\n",
    "\n",
    "Our goal for this analysis is to be able to determine which model is able to more accurately predict what are the top restaurants in the locale (possibly depending on cuisines, locality, or average price.) <!-- Expound >\n",
    "\n",
    "**1. Data Preprocessing**\n",
    "- Load and Inspection of data.\n",
    "- Cleaning the data (i.e. Tableau) <!-- care of Godwyn -->\n",
    "\n",
    "**2. Exploratory Data Analysis (EDA)**\n",
    "- This will be more on understanding which features create a reactive effect towards the rest of the feature. \n",
    "- Identifies which feature is able to change the course of the data. From there, we will implement the models.\n",
    "\n",
    "**3. Decision Tree Implementation 1 (DT1)**\n",
    "- This will be one of the initial basis of our model apart from EDA.\n",
    "\n",
    "**4. Apply Decision Tree Implementation 2 (DT2)**\n",
    "- The second implementation of Decision Tree will consist of the data set where we have omitted certain features (To be identified soon. _i.e., MISSING values, certain irrelevant features_) based on our domain knowledge.\n",
    "- Comparing this to Decision Tree Implementation 1, we may be able to justify that omitting certain \"junk\" features can make Decision Tree model more accurate.\n",
    "\n",
    "**5. Apply Mixed Naive Bayes (MNB)**\n",
    "- The final model we use in this study is the Mixed Naive Bayes (MNB) classifier. This model is a variation of the standard Naive Bayes algorithm that allows us to handle both categorical and continuous featuresâ€”whic makes it especially well-suited for real-world datasets like Zomatoâ€™s, where variables such as cuisine type (categorical) and average price (numerical) coexist.\n",
    "\n",
    "**6. Conclusion**\n",
    "- Generally, through ***Exploratory Data Analysis (EDA) and both Decision Tree implementations***, you may conclude that certain featuresâ€”such as Cuisine type, Locality, or Average Priceâ€”have a strong influence on whether a restaurant receives high ratings. _Features like 'MISSING' or non-informative columns could be confirmed as noise, negatively affecting model accuracy._\n",
    "- Comparing ***Decision Tree 1 (all features) with Decision Tree 2 (cleaned features)***, you might find that:\n",
    "    - Removing irrelevant or noisy features leads to higher accuracy and simpler tree structures.\n",
    "    - This supports the idea that domain knowledge-based feature pruning improves model performance.\n",
    "- ***Mixed Naive Bayes (MNB) might perform competitively or better on some metrics*** (like precision or recall) compared to Decision Trees, especially in cases where feature independence is mostly true. However, MNB might underperform if features are highly correlated, where Decision Trees can better handle interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b1a50",
   "metadata": {},
   "source": [
    "# **IV. Data Preprocessing**\n",
    "\n",
    "< This section will include general importing and inspection of the data. Cleaning the data as well for nullified or duplicated values. > <!-- Expound more >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume that we do not have the necessary libraries installed. \n",
    "%pip install pandas numpy matplotlib seaborn scikit-learn mixed-naive-bayes #This is to install the libraries needed to run the code.\n",
    "%pip install --upgrade pip #Updates pip\n",
    "\n",
    "# Need to install tkinter.\n",
    "# For mac: brew install python-tk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold ## https://www.geeksforgeeks.org/cross-validation-machine-learning/\n",
    "from mixed_naive_bayes import MixedNB\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "## Use if you are using Google Drive\n",
    "import io\n",
    "\n",
    "## Use if you are using Google Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If using Jupyter Notebook / Run Locally via VS Code. Import the file LOZADA, BINWAG, CSCI 211 Zomato Dataset Pune.csv\n",
    "# Hardcoded file path to your dataset\n",
    "file_path = \"LOZADA, BINWAG, CSCI 211 Zomato Dataset Pune.csv\"\n",
    "zomato_pune = pd.read_csv(file_path)\n",
    "\n",
    "# Create a working copy for analysis\n",
    "zomato_for_eda = zomato_pune.copy()\n",
    "\n",
    "# Display the data\n",
    "zomato_for_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16169d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data\n",
    "zomato_for_eda.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b2cb9",
   "metadata": {},
   "source": [
    "## **Restaurant Count per Locality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count restaurants per locality\n",
    "locality_counts = zomato_for_eda['Locality in Pune'].value_counts()\n",
    "\n",
    "# Plot the top 15\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=locality_counts.head(15).values, y=locality_counts.head(15).index, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Top 15 Localities by Number of Restaurants\")\n",
    "plt.xlabel(\"Number of Restaurants\")\n",
    "plt.ylabel(\"Locality\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691fb74",
   "metadata": {},
   "source": [
    "## **Listing All Cuisines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cdb774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of cuisine columns\n",
    "cuisine_cols = [f'Cuisine{i}' for i in range(1, 9)]\n",
    "\n",
    "# Flatten, drop NAs and \"MISSING\", then get unique values\n",
    "all_cuisines = pd.unique(\n",
    "    zomato_for_eda[cuisine_cols]\n",
    "    .values\n",
    "    .ravel()\n",
    ")\n",
    "\n",
    "# Clean list\n",
    "unique_cuisines = sorted([c for c in all_cuisines if pd.notna(c) and c != 'MISSING'])\n",
    "\n",
    "# Display\n",
    "print(\"Number of unique cuisines:\", len(unique_cuisines))\n",
    "print(unique_cuisines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec51c3",
   "metadata": {},
   "source": [
    "## **Correlation between Pricing_for_2 and Dining_Rating.**\n",
    "This is to be able to understand if pricing is \"cheaper\" gains a better rating as a restaurant. However, this is just a shallow experiment as Pricing can't be the only factor in a high-rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede7d86-264e-4016-9fd4-6c8d7008ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(zomato_for_eda['Pricing_for_2'], zomato_for_eda['Dining_Rating'], gridsize=30, cmap='Blues')\n",
    "plt.colorbar(label='Count in Bin')\n",
    "plt.xlabel('Pricing for 2')\n",
    "plt.ylabel('Dining Rating')\n",
    "plt.title('Hexbin: Price vs Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e023ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = zomato_for_eda[['Pricing_for_2', 'Dining_Rating']].corr()\n",
    "print(\"Correlation between Pricing and Rating:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cea287",
   "metadata": {},
   "source": [
    "## **Correlation between Locality and Cuisine (1-8) to Dining_Rating.**\n",
    "We proceed to test if there is a correlation between a cuisine served in certain locality. Such that, if for instance, `Mediterranean` and `European` cuisines served in\t`Koregaon Park` receives a high rating whilst `Coffee` and `Desserts` served in the same locale has low-ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ac8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape cuisine columns into one\n",
    "cuisine_cols = [f'Cuisine{i}' for i in range(1, 9)]\n",
    "\n",
    "# Melt cuisine columns\n",
    "long_df = zomato_for_eda.melt(\n",
    "    id_vars=['Dining_Rating', 'Locality in Pune'],\n",
    "    value_vars=cuisine_cols,\n",
    "    var_name='CuisineCol',\n",
    "    value_name='Cuisine'\n",
    ")\n",
    "\n",
    "# Drop missing cuisines\n",
    "long_df = long_df.dropna(subset=['Cuisine'])\n",
    "\n",
    "# Grouping\n",
    "rating_by_combo = (\n",
    "    long_df\n",
    "    .groupby(['Cuisine', 'Locality in Pune'])['Dining_Rating']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Dining_Rating': 'Avg_Rating'})\n",
    ")\n",
    "\n",
    "# Top 15 highest-rated cuisine-location combos.\n",
    "# Maintains the original index of the row.\n",
    "rating_by_combo.sort_values('Avg_Rating', ascending=False).head(15)\n",
    "\n",
    "# Revises the index starting from 0.\n",
    "# Uncomment if prefer to use original indexing.\n",
    "    # cleaned_top = rating_by_combo.sort_values('Avg_Rating', ascending=False).head(15).reset_index(drop=True)\n",
    "    # cleaned_top # Prints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to threshold. Only Avg_Rating over 3.8\n",
    "filtered = rating_by_combo[rating_by_combo['Avg_Rating'] > 3.8]\n",
    "\n",
    "# Keep only top cuisines and localities by frequency\n",
    "top_cuisines = (\n",
    "    long_df['Cuisine'].value_counts()\n",
    "    .loc[lambda x: x.index != 'MISSING']\n",
    "    .head(10).index\n",
    ")\n",
    "\n",
    "top_localities = long_df['Locality in Pune'].value_counts().head(10).index\n",
    "\n",
    "# Apply filter\n",
    "filtered = filtered[\n",
    "    (filtered['Cuisine'].isin(top_cuisines)) &\n",
    "    (filtered['Locality in Pune'].isin(top_localities))\n",
    "]\n",
    "\n",
    "# Pivot\n",
    "heatmap_data = filtered.pivot(\n",
    "    index=\"Cuisine\",\n",
    "    columns=\"Locality in Pune\",\n",
    "    values=\"Avg_Rating\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Dining Rating > 3.8 â€” Top 10 Cuisines x Top 5 Localities\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fa270",
   "metadata": {},
   "source": [
    "## **Price Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filter the dataset\n",
    "filtered = zomato_for_eda[zomato_for_eda['Dining_Rating'] >= 3.8]\n",
    "\n",
    "# Plot histogram with KDE\n",
    "sns.histplot(filtered['Pricing_for_2'], bins=20, kde=False, color='seagreen')\n",
    "plt.title(\"Price Distribution for Restaurants with Rating â‰¥ 3.8\")\n",
    "plt.xlabel(\"Price for 2\")\n",
    "plt.ylabel(\"Number of Restaurants\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the features and filter the DataFrame\n",
    "input_features = [\"Cuisine1\", \"Cuisine2\", \"Cuisine3\", \"Cuisine4\", \n",
    "                  \"Cuisine5\", \"Cuisine6\", \"Cuisine7\", \"Cuisine8\", \n",
    "                  \"Pricing_for_2\", \"Locality in Pune\"]\n",
    "\n",
    "X = zomato_for_eda.filter(items=input_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Flatten all cuisines\n",
    "cuisine_cols = [f'Cuisine{i}' for i in range(1, 9)]\n",
    "cuisines_flat = pd.Series(X[cuisine_cols].values.ravel())\n",
    "\n",
    "# Step 2: Clean values\n",
    "cuisines_flat = cuisines_flat.replace(\"MISSING\", np.nan).dropna()\n",
    "\n",
    "# Step 3: Count top 15\n",
    "cuisines_freq = cuisines_flat.value_counts().head(15)\n",
    "\n",
    "# Step 4: Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=cuisines_freq.values, y=cuisines_freq.index)\n",
    "plt.title(\"Top 15 Most Common Cuisines\")\n",
    "plt.xlabel(\"Number of Occurrences\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7251b4f",
   "metadata": {},
   "source": [
    "## **More EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76938ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set rating threshold\n",
    "rating_threshold = 3.75\n",
    "\n",
    "# First-level helper functions\n",
    "def find_percent(df, feature_group, feature):\n",
    "    feature_filter = df.loc[df[feature_group] == feature]\n",
    "    if not feature_filter.empty:\n",
    "        percent_above_cutoff = 100 - percentileofscore(\n",
    "            feature_filter['Dining_Rating'], rating_threshold, kind='strict'\n",
    "        )\n",
    "    else:\n",
    "        percent_above_cutoff = 0\n",
    "    return percent_above_cutoff\n",
    "\n",
    "def find_mean_rating(df, feature_group, feature):\n",
    "    feature_filter = df.loc[df[feature_group] == feature]\n",
    "    return feature_filter['Dining_Rating'].mean() if not feature_filter.empty else np.nan\n",
    "\n",
    "# Second-level EDA helper\n",
    "def eda_resto_data_numerical(df, feature_group):\n",
    "    feature_list = pd.unique(df[feature_group]).tolist()\n",
    "    feature_list2 = [feature for feature in feature_list if feature != 'MISSING' and pd.notnull(feature)]\n",
    "\n",
    "    percent_exceeding_cutoff_feature = []\n",
    "    average_per_cutoff_feature = []\n",
    "\n",
    "    for feature in feature_list2:\n",
    "        above_threshold = round(find_percent(df, feature_group, feature), 4)\n",
    "        percent_exceeding_cutoff_feature.append(above_threshold)\n",
    "\n",
    "        mean_rating = round(find_mean_rating(df, feature_group, feature), 4)\n",
    "        average_per_cutoff_feature.append(mean_rating)\n",
    "\n",
    "    # MinMax scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    mean_scaled = scaler.fit_transform(np.array(average_per_cutoff_feature).reshape(-1, 1)).flatten()\n",
    "    mean_scaled = [round(score, 4) for score in mean_scaled]\n",
    "\n",
    "    # Create summary DataFrame\n",
    "    df_mean_feature = pd.DataFrame({\n",
    "        feature_group: feature_list2,\n",
    "        '% Above 3.75': percent_exceeding_cutoff_feature,\n",
    "        'Mean Rating': average_per_cutoff_feature,\n",
    "        'MinMax Scale Score': mean_scaled\n",
    "    })\n",
    "\n",
    "    df_mean_feature = df_mean_feature.sort_values(by=['Mean Rating', feature_group], ascending=[False, True]).reset_index(drop=True)\n",
    "    df_mean_feature['Rank'] = df_mean_feature.index + 1\n",
    "\n",
    "    return df_mean_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_locality = eda_resto_data_numerical(zomato_for_eda, 'Locality in Pune')\n",
    "eda_locality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine1 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine1')\n",
    "eda_resto_cuisine1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d169160",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine2 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine2')\n",
    "eda_resto_cuisine2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine3 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine3')\n",
    "eda_resto_cuisine3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine4 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine4')\n",
    "eda_resto_cuisine4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine5 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine5')\n",
    "eda_resto_cuisine5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine6 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine6')\n",
    "eda_resto_cuisine6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine7 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine7')\n",
    "eda_resto_cuisine7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d06bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_resto_cuisine8 = eda_resto_data_numerical(zomato_for_eda, 'Cuisine8')\n",
    "eda_resto_cuisine8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato_pune_yes = zomato_for_eda[zomato_for_eda['Dining_Rating'] >= 3.8]\n",
    "zomato_pune_yes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato_pune_no = zomato_for_eda[zomato_for_eda['Dining_Rating'] < 3.8]\n",
    "zomato_pune_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db27aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cost = min(zomato_pune_yes['Pricing_for_2'])\n",
    "max_cost = max(zomato_pune_yes['Pricing_for_2'])\n",
    "\n",
    "num_bins = int((max_cost - min_cost) / 50) + 1\n",
    "num_bins\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(zomato_pune_yes['Pricing_for_2'], bins = num_bins, color='magenta')\n",
    "plt.title(\"Meal Cost Distribution of the Zomato Dataset in Pune (if rating >= 3.8)\")\n",
    "plt.xlabel(\"Cost of Meal for 2 (INR)\")\n",
    "plt.xlim(0, 5000)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd55d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cost = min(zomato_pune_no['Pricing_for_2'])\n",
    "max_cost = max(zomato_pune_no['Pricing_for_2'])\n",
    "\n",
    "num_bins = int((max_cost - min_cost) / 50) + 1\n",
    "num_bins\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(zomato_pune_no['Pricing_for_2'], bins = num_bins, color='red')\n",
    "plt.title(\"Meal Cost Distribution of the Zomato Dataset in Pune (if rating < 3.8)\")\n",
    "plt.xlabel(\"Cost of Meal for 2 (INR)\")\n",
    "plt.xlim(0, 5000)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map the cuisines to numerical features according\n",
    "\n",
    "def feature_map(feature_df, row_feature):\n",
    "    feature_map = {'MISSING' : 0}\n",
    "\n",
    "    for index, row in feature_df.iterrows():\n",
    "        feature_name = row[row_feature]\n",
    "        rank = row['Rank']\n",
    "\n",
    "        feature_map[feature_name] = rank\n",
    "    return feature_map\n",
    "\n",
    "# Create mappings for cuisine 1 to cuisine 8\n",
    "cuisine1_map = feature_map(eda_resto_cuisine1, 'Cuisine1')\n",
    "cuisine2_map = feature_map(eda_resto_cuisine2, 'Cuisine2')\n",
    "cuisine3_map = feature_map(eda_resto_cuisine3, 'Cuisine3')\n",
    "cuisine4_map = feature_map(eda_resto_cuisine4, 'Cuisine4')\n",
    "cuisine5_map = feature_map(eda_resto_cuisine5, 'Cuisine5')\n",
    "cuisine6_map = feature_map(eda_resto_cuisine6, 'Cuisine6')\n",
    "cuisine7_map = feature_map(eda_resto_cuisine7, 'Cuisine7')\n",
    "cuisine8_map = feature_map(eda_resto_cuisine8, 'Cuisine8')\n",
    "\n",
    "# Create mapping for locality\n",
    "locality_map = feature_map(eda_locality, 'Locality in Pune')\n",
    "\n",
    "# map the columns for cuisine\n",
    "zomato_for_eda['Cuisine1'] = zomato_for_eda['Cuisine1'].map(cuisine1_map)\n",
    "zomato_for_eda['Cuisine2'] = zomato_for_eda['Cuisine2'].map(cuisine2_map)\n",
    "zomato_for_eda['Cuisine3'] = zomato_for_eda['Cuisine3'].map(cuisine3_map)\n",
    "zomato_for_eda['Cuisine4'] = zomato_for_eda['Cuisine4'].map(cuisine4_map)\n",
    "zomato_for_eda['Cuisine5'] = zomato_for_eda['Cuisine5'].map(cuisine5_map)\n",
    "zomato_for_eda['Cuisine6'] = zomato_for_eda['Cuisine6'].map(cuisine6_map)\n",
    "zomato_for_eda['Cuisine7'] = zomato_for_eda['Cuisine7'].map(cuisine7_map)\n",
    "zomato_for_eda['Cuisine8'] = zomato_for_eda['Cuisine8'].map(cuisine8_map)\n",
    "\n",
    "# Map the columns for locality in Pune\n",
    "zomato_for_eda['Locality in Pune'] = zomato_for_eda['Locality in Pune'].map(locality_map)\n",
    "\n",
    "# Create binary classification column\n",
    "zomato_for_eda['isHighRating'] = (zomato_for_eda['Dining_Rating'] >= rating_threshold).astype(int)\n",
    "\n",
    "# Drop the original numerical rating column\n",
    "zomato_for_eda = zomato_for_eda.drop(columns=['Dining_Rating'])\n",
    "\n",
    "# Reorder columns to ensure binary classification is at the rightmost position\n",
    "zomato_for_eda = zomato_for_eda[[col for col in zomato_for_eda.columns if col not in ['isHighRating']] + ['isHighRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\"Cuisine1\", \"Cuisine2\", \"Cuisine3\", \"Cuisine4\", \"Cuisine5\", \"Cuisine6\", \"Cuisine7\", \"Cuisine8\", \"Pricing_for_2\", \"Locality in Pune\"]\n",
    "\n",
    "X = zomato_for_eda.filter(items = input_features)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdabbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = zomato_for_eda[\"isHighRating\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216f52c",
   "metadata": {},
   "source": [
    "## **Post-EDA**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456cb84",
   "metadata": {},
   "source": [
    "After reviewing the data, we've understood the following.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766b69b",
   "metadata": {},
   "source": [
    "# **V. Decision Tree Implementation 1 (DT1)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 70% train, 30% others (as a working concept, assume that other)\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, test_size = 0.3, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee84e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier(random_state = 45)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dec_tree.predict(X_other)\n",
    "cm = confusion_matrix(y_other, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels = dec_tree.classes_)\n",
    "cm_display.plot(cmap = plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f58b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "accuracy = accuracy_score(y_other, y_pred)\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"Sensitivity: {sensitivity*100:.2f} %\")\n",
    "print(f\"Specificity: {specificity*100:.2f} %\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dcba77",
   "metadata": {},
   "source": [
    "The current Decisition Tree (DT1) implementation consists of the basic cleaned data. This means that we've decided to keep the `MISSING` values that occur in the way the data is collected. While restaurants may have 1-2 cuisines, some have over 2 cuisines served. This is the reason why there is `cuisine 1 to 8` in the dataset. As such, `MISSING` values may incur false-negative results in predicting `Dining_Ratings`. In this case, DT1 has an accuracy of `62.08%`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce3a1c",
   "metadata": {},
   "source": [
    "## **VI. Decision Tree Implementation 2 (DT2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e5aa5",
   "metadata": {},
   "source": [
    "For DT2, the dataset has been further cleaned by removing ` MISSING ` values and making sure that there are no _\"Junk\"_ data that possibly makes Decision Trees lose its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9465968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'MISSING' (0) with -1\n",
    "cuisine_cols = [f'Cuisine{i}' for i in range(1, 9)]\n",
    "X_all = zomato_for_eda.drop(columns=['isHighRating']).copy()\n",
    "X_all[cuisine_cols] = X_all[cuisine_cols].replace(0, -1)\n",
    "\n",
    "# Keep only numeric columns (drop Restaurant_Name etc.)\n",
    "X_clean = X_all.select_dtypes(include=[np.number])\n",
    "y_clean = zomato_for_eda['isHighRating']\n",
    "\n",
    "# Train-test split\n",
    "X_train2, X_other2, y_train2, y_other2 = train_test_split(X_clean, y_clean, test_size=0.3, random_state=45)\n",
    "\n",
    "# Train the model\n",
    "dec_tree2 = DecisionTreeClassifier(random_state=45)\n",
    "dec_tree2.fit(X_train2, y_train2)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = dec_tree2.predict(X_other2)\n",
    "cm2 = confusion_matrix(y_other2, y_pred2)\n",
    "cm_display2 = ConfusionMatrixDisplay(cm2, display_labels=dec_tree2.classes_)\n",
    "cm_display2.plot(cmap=plt.cm.Greens)\n",
    "plt.title(\"Confusion Matrix for Decision Tree 2\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "tn2, fp2, fn2, tp2 = cm2.ravel()\n",
    "sensitivity2 = tp2 / (tp2 + fn2) if (tp2 + fn2) != 0 else 0\n",
    "specificity2 = tn2 / (tn2 + fp2) if (tn2 + fp2) != 0 else 0\n",
    "accuracy2 = accuracy_score(y_other2, y_pred2)\n",
    "\n",
    "print(f\"ðŸ“Š Decision Tree 2 Metrics (Ignoring MISSING features):\")\n",
    "print(f\"True Positives: {tp2}\")\n",
    "print(f\"Sensitivity: {sensitivity2*100:.2f} %\")\n",
    "print(f\"Specificity: {specificity2*100:.2f} %\")\n",
    "print(f\"Accuracy: {accuracy2*100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f15743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_importances = pd.Series(dec_tree2.feature_importances_, index=X_clean.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "print(feature_importances.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967c91e",
   "metadata": {},
   "source": [
    "## **VII. Mixed Naive Bayes (MNB)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a81e50",
   "metadata": {},
   "source": [
    "Implementing MNB to the cleaned dataset (_same with cleaned dataset of DT2_). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42955603",
   "metadata": {},
   "source": [
    "## **VIII. General Finding and Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702983a7",
   "metadata": {},
   "source": [
    "Explaining what we've found. (i.e., DT1 showed an accuracy of 60%.. However, DT2 as predicted, was able to get an accuracy of 80%... And lastly, MNB was able to get an accuracy of...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc60b2",
   "metadata": {},
   "source": [
    "## **IX. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59edc5",
   "metadata": {},
   "source": [
    "Based on the findings, it is evident that DT2 and MNB was able to accurately predict... as such, we think it would be more accurate to remove _\"Junk\"_ data such as `MISSING, NULL, -12931931, 13412131` that can affect the model in predicting. \n",
    "\n",
    "In the case of predicting ` dining ratings `, it is possible that there could be a better model to be used since **Decision Trees** and **Mixed Naive Bayes** are only able to get `x%` and `y%`. Judging from the dataset, it may be even viable to use **Ensemble Learning Models (random forest)**, or the need to heavily manipulate the data to accomodate ` MISSING ` values and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ba363",
   "metadata": {},
   "source": [
    "## **X. References**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
